{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mud card\n",
    "\n",
    "- **Could you specify on the baseline of accuracy in the spam email example?**\n",
    "- **how unbalanced data affects good accuracy values**\n",
    "    - the baseline accuracy is determined using the target variable of the training set\n",
    "    - the baseline accuracy is the fraction of points in the most populous class\n",
    "        - if 5% of emails are spam, and 95% of emails are not spam, 0.95 is the baseline accuracy because if you predict 'non-spam' for each point, you will be correct 95% of the times.\n",
    "    - the baseline is calculated differently for other evaluation metrics\n",
    "    - the general concept is to use the target variable only (no features) to figure out the baseline\n",
    "    - we will cover this later\n",
    "- **\"What is the alternative to the hard-coded cross validation loop? Is there a sci-kit learn function for running cross-validation and tuning hyperparameters at this stage?**\n",
    "    - yes there is and we will learn about it once you have solid foundations of the more basic techniques\n",
    "    - the issue is that these one-line scikit-learn solutions hide a lot of stuff from you so you should only use them if you know exactly what you are doing.\n",
    "- **Before this stage, during the train-test split, how important is training (10 models) using random_state_... is this just for small datasets?**\n",
    "    - the smaller you dataset, the more important it is\n",
    "    - generally speaking it is always a good idea to try at least 3 random states even if you dataset is large if you can manage it given your computational resources\n",
    "- **I do not have much experience in coding, and am not a 100% sure what each line of code in the examples do or represent - what are some resources I can look into to understand what is happening line by line?**\n",
    "- **I didn't understand the syntax and code of splitting**\n",
    "- **Maybe more clear explaination on the code**\n",
    "- **Would you be able to walk through the code for hyper tuning again? How did you come up with the parameters for np.logspace?**\n",
    "    - you should read the help of each function used in a line and print out all variables used in a line to know what's happening and how variables change\n",
    "- **If a new data point has a predicted probability of 0.2 does that mean it has an 80% probability that its target value will be 0?**\n",
    "    - depends. you will see that classification models return two columns when you predict probabilities: the class 0 probability and the class 1 probability\n",
    "    - the two probabilities sum to 1 for each point\n",
    "    - if the class 0 probability is 0.2, it means the point is class 1 with 80% probability\n",
    "    - if the class 1 probability is 0.2, it means the point is class 0 with 80% probability\n",
    "- **How does SVM work? Is it like linear regression, but the line is curvy**\n",
    "- **What exactly is C?**\n",
    "- **what is c mean for SVC**\n",
    "- **I am still unclear about what C is or what the hyperparameters are in the context of a ML algorithm.**\n",
    "    - it is a non-linear model and we will cover it in a few weeks\n",
    "- **I was a bit confused on the ML techniques portion. Will we eventually learn such techniques and when to apply them?**\n",
    "    - yes :)\n",
    "- **Could you please discuss bias-variance tradeoff again in the next class? Along with a few more real-time examples and how it can affect a data science project?**\n",
    "- **I am still a little confused about finding the ideal fit of the model based on the graph showing the c parameter and accuracy.**\n",
    "- **I thought the muddiest part of the lecture was the bias-variance tradeoff**\n",
    "- **Why is it necessary to have test and validation sets?**\n",
    "- **Could you explain in more detail what \"validation\" means and how its different from testing?**\n",
    "- **I was still a little unsure what the difference between validation and testing is?**\n",
    "- **I'm struggling with tuning the hyperparameters.**\n",
    "- **Parts 5-7 and c-values/cross validation in general just went over my head.**\n",
    "- **Still not quite clear on the rationale for validation vs. test set - what's the actual distinction?**\n",
    "    - I'll cover this again now\n",
    "- **What is the differencfe between X and Y and Curly XY?**\n",
    "    - curly X and curly Y are the sets of all possible instances and target variables\n",
    "    - regular X and Y are a (usually small) sample drawn from curly X and curly Y\n",
    "- **How do you know when you have done 'enough' EDA for a given dataset?**\n",
    "    - you don't know :) \n",
    "    - but at the very least you should know what each feature in your dataset means, you should know the typical summary statistics of each feature (we will discuss summary stats next tuesday)\n",
    "    - ML pipeline development is non-linear. we cover the steps in a linear fashion but sometimes you need to do more EDA after you do cross validation because something doesn't seem OK in your results for example\n",
    "- **And will we go over what characteristics we see in EDA that point to different ML methods?**\n",
    "    - such insights are very rare. generally you need to try as many models as you can. \n",
    "    - it is rare that you can exclude a ML model based on EDA\n",
    "- **How do we know the bounds and scale for hyperparameter tuning? For instance, the examples uses logscale.**\n",
    "    - we will cover this for each ML technique separately in a couple of weeks\n",
    "- **Once we get an optimal hyper parameter for one random state split of our data, do we then use that C retroactively for each random state we test after that?**\n",
    "    - no, you would determine an optimal C for each random state\n",
    "    - you might find that different Cs are optimal for different random states\n",
    "- **What other evaluation metrics are common and how do we determine which is appropriate?**\n",
    "    - we will spend a week on this question :)\n",
    "- **It would have been better if there were an example table of the learner's input , especially the label set Y.**\n",
    "- **Needs to know the basic concept of data set**\n",
    "    - open the toy_data.csv in the data folder, that's a good example of a simple dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Exploratory data analysis in python, part 1 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The steps\n",
    "\n",
    "<span style=\"background-color: #FFFF00\">**1. Exploratory Data Analysis (EDA)**: you need to understand your data and verify that it doesn't contain errors</span>\n",
    "   - do as much EDA as you can!\n",
    "    \n",
    "**2. Split the data into different sets**: most often the sets are train, validation, and test (or holdout)\n",
    "   - practitioners often make errors in this step!\n",
    "   - you can split the data randomly, based on groups, based on time, or any other non-standard way if necessary to answer your ML question\n",
    "\n",
    "**3. Preprocess the data**: ML models only work if X and Y are numbers! Some ML models additionally require each feature to have 0 mean and 1 standard deviation (standardized features)\n",
    "   - often the original features you get contain strings (for example a gender feature would contain 'male', 'female', 'non-binary', 'unknown') which needs to transformed into numbers\n",
    "   - often the features are not standardized (e.g., age is between 0 and 100) but it needs to be standardized\n",
    "    \n",
    "**4. Choose an evaluation metric**: depends on the priorities of the stakeholders\n",
    "   - often requires quite a bit of thinking and ethical considerations\n",
    "     \n",
    "**5. Choose one or more ML techniques**: it is highly recommended that you try multiple models\n",
    "   - start with simple models like linear or logistic regression\n",
    "   - try also more complex models like nearest neighbors, support vector machines, random forest, etc.\n",
    "    \n",
    "**6. Tune the hyperparameters of your ML models (aka cross-validation)**\n",
    "   - ML techniques have hyperparameters that you need to optimize to achieve best performance\n",
    "   - for each ML model, decide which parameters to tune and what values to try\n",
    "   - loop through each parameter combination\n",
    "       - train one model for each parameter combination\n",
    "       - evaluate how well the model performs on the validation set\n",
    "   - take the parameter combo that gives the best validation score\n",
    "   - evaluate that model on the test set to report how well the model is expected to perform on previously unseen data\n",
    "    \n",
    "**7. Interpret your model**: black boxes are often not useful\n",
    "   - check if your model uses features that make sense (excellent tool for debugging)\n",
    "   - often model predictions are not enough, you need to be able to explain how the model arrived to a particular prediction (e.g., in health care)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Pandas </center>\n",
    "\n",
    "- data are often distributed over multiple files/databases (e.g., csv and excel files, sql databases)\n",
    "- each file/database is read into a pandas dataframe\n",
    "- you often need to filter dataframes (select specific rows/columns based on index or condition)\n",
    "- pandas dataframes can be merged and appended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some notes and advice\n",
    "\n",
    "- **ALWAYS READ THE HELP OF THE METHODS/FUNCTIONS YOU USE!**\n",
    "\n",
    "- stackoverflow is your friend, use it! https://stackoverflow.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Data transformations: pandas data frames </center>\n",
    "### By the end of this lecture, you will be able to\n",
    "   - read in csv, excel, and sql data into a pandas data frame\n",
    "   - filter rows in various ways\n",
    "   - select columns\n",
    "   - merge and append data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color='LIGHTGRAY'><center> Data transformations: pandas data frames </center></font>\n",
    "###  <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "   - **read in csv, excel, and sql data into a pandas data frame**\n",
    "   -  <font color='LIGHTGRAY'>filter rows in various ways</font>\n",
    "   -  <font color='LIGHTGRAY'>select columns</font>\n",
    "   -  <font color='LIGHTGRAY'>merge and append data frames</font>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 8,
>>>>>>> Stashed changes
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# how to read in a database into a dataframe and basic dataframe structure\n",
    "import pandas as pd\n",
    "\n",
    "# load data from a csv file\n",
    "df = pd.read_csv('data/adult_data.csv') # there are also pd.read_excel(), and pd.read_sql()\n",
    "\n",
    "print(df)\n",
    "#help(df.head)\n",
    "#print(df.head(10)) # by default, shows the first five rows but check help(df.head) to specify the number of rows to show\n",
    "#print(df.shape) # the shape of your dataframe (number of rows, number of columns)\n",
    "#print(df.shape[0]) # number of rows\n",
    "#print(df.shape[1]) # number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Packages\n",
    "\n",
    "A package is a collection of classes and functions.\n",
    "- a dataframe (pd.DataFrame()) is a pandas class\n",
    "    - a class is the blueprint of how the data should be organized \n",
    "    - classes have methods which can perform operations on the data (e.g., .head(), .shape)\n",
    "- df is an object, an instance of the class.\n",
    "    - we put data into the class \n",
    "    - methods are attached to objects \n",
    "       - you cannot call pd.head(), you can only call df.head()\n",
    "- read_csv is a function\n",
    "    - functions are called from the package\n",
    "    - you cannot call df.read_csv, you can only call pd.read_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DataFrame structure: both rows and columns are indexed!\n",
    "- index column, no name\n",
    "    - contains the row names\n",
    "    - by default, index is a range object from 0 to number of rows - 1 \n",
    "    - any column can be turned into an index, so indices can be non-number, and also non-unique. more on this later.\n",
    "- columns with column names on top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Always print your dataframe to check if it looks ok!\n",
    "\n",
    "### Most common reasons it might not look ok:\n",
    "\n",
    "   - the first row is not the column name\n",
    "        - there are rows above the column names that need to be skipped\n",
    "        - there is no column name but by default, pandas assumes the first row is the column name. as a result, \n",
    "          the values of the first row end up as column names.\n",
    "   - character encoding is off\n",
    "   - separator is not comma but some other charachter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# check the help to find the solution\n",
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "How should we read in adult_test.csv properly? Identify and fix the problem."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 6,
>>>>>>> Stashed changes
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  This is the test set for the adult dataset.  Unnamed: 1 Unnamed: 2  \\\n",
      "0     The first two lines need to be skipped.         NaN        NaN   \n",
      "1                                         age   workclass     fnlwgt   \n",
      "2                                          25     Private     226802   \n",
      "3                                          38     Private      89814   \n",
      "4                                          28   Local-gov     336951   \n",
      "\n",
      "    Unnamed: 3     Unnamed: 4           Unnamed: 5          Unnamed: 6  \\\n",
      "0          NaN            NaN                  NaN                 NaN   \n",
      "1    education  education-num       marital-status          occupation   \n",
      "2         11th              7        Never-married   Machine-op-inspct   \n",
      "3      HS-grad              9   Married-civ-spouse     Farming-fishing   \n",
      "4   Assoc-acdm             12   Married-civ-spouse     Protective-serv   \n",
      "\n",
      "     Unnamed: 7 Unnamed: 8 Unnamed: 9   Unnamed: 10   Unnamed: 11  \\\n",
      "0           NaN        NaN        NaN           NaN           NaN   \n",
      "1  relationship       race        sex  capital-gain  capital-loss   \n",
      "2     Own-child      Black       Male             0             0   \n",
      "3       Husband      White       Male             0             0   \n",
      "4       Husband      White       Male             0             0   \n",
      "\n",
      "      Unnamed: 12     Unnamed: 13   Unnamed: 14  \n",
      "0             NaN             NaN           NaN  \n",
      "1  hours-per-week  native-country  gross-income  \n",
      "2              40   United-States        <=50K.  \n",
      "3              50   United-States        <=50K.  \n",
      "4              40   United-States         >50K.  \n"
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "df = pd.read_csv('data/adult_test.csv',skiprows=2)\n",
=======
    "import pandas as pd\n",
    "df = pd.read_csv('data/adult_test.csv', header = 2)\n",
>>>>>>> Stashed changes
    "print(df.head()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color='LIGHTGRAY'><center> Data transformations: pandas data frames </center></font>\n",
    "###  <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "   - <font color='LIGHTGRAY'>read in csv, excel, and sql data into a pandas data frame</font>\n",
    "   -  **filter rows in various ways**\n",
    "   -  <font color='LIGHTGRAY'>select columns</font>\n",
    "   -  <font color='LIGHTGRAY'>merge and append data frames</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to select rows?\n",
    "\n",
    "##### 1) Integer-based indexing, numpy arrays are indexed the same way.\n",
    "##### 2) Select rows based on the value of the index column\n",
    "##### 3) select rows based on column condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1) Integer-based indexing, numpy arrays are indexed the same way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# df.iloc[] - for more info, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-integer\n",
    "# iloc is how numpy arrays are indexed (non-standard python indexing)\n",
    "\n",
    "# [start:stop:step] -  general indexing format\n",
    "\n",
    "# start stop step are optional\n",
    "#print(df.iloc[:])\n",
    "#print(df.iloc[::])\n",
    "#print(df.iloc[::1])\n",
    "\n",
    "# select one row - 0-based indexing\n",
    "#print(df.iloc[3])\n",
    "\n",
    "# indexing from the end of the data frame\n",
    "#print(df.iloc[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# select a slice - stop index not included\n",
    "#print(df.iloc[3:7])\n",
    "\n",
    "# select every second element of the slice - stop index not included\n",
    "#print(df.iloc[3:7:2])\n",
    "\n",
    "#print(df.iloc[3:7:-2]) # return empty dataframe\n",
    "#print(df.iloc[7:3:-2])#  return rows with indices 7 and 5. 3 is the stop so it is not included\n",
    "\n",
    "# can be used to reverse rows\n",
    "#print(df.iloc[::-1])\n",
    "\n",
    "# here is where indexing gets non-standard python\n",
    "# select the 2nd, 5th, and 10th rows\n",
    "print(df.iloc[[1,4,9]]) # such indexing doesn't work with lists but it works with numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### 2) Select rows based on the value of the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# df.loc[] - for more info, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-label\n",
    "\n",
    "print(df.index) # the default index when reading in a file is a range index. In this case,\n",
    "                 # .loc and .iloc works ALMOST the same.\n",
    "# one difference:\n",
    "#print(df.loc[3:9:2]) # this selects the 4th, 6th, 8th, 10th rows - the stop element is included!\n",
    "\n",
    "#help(df.set_index)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> Stashed changes
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([39, 50, 38, 53, 28, 37, 49, 52, 31, 42,\n",
      "            ...\n",
      "            32, 43, 32, 53, 22, 27, 40, 58, 22, 52],\n",
      "           dtype='int64', name='age', length=32561)\n",
      "     age          workclass  fnlwgt   education  education-num  \\\n",
      "age                                                              \n",
      "39    39          State-gov   77516   Bachelors             13   \n",
      "50    50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "38    38            Private  215646     HS-grad              9   \n",
      "53    53            Private  234721        11th              7   \n",
      "28    28            Private  338409   Bachelors             13   \n",
      "\n",
      "          marital-status          occupation    relationship    race      sex  \\\n",
      "age                                                                             \n",
      "39         Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "50    Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "38              Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "53    Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "28    Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "     capital-gain  capital-loss  hours-per-week  native-country gross-income  \n",
      "age                                                                           \n",
      "39           2174             0              40   United-States        <=50K  \n",
      "50              0             0              13   United-States        <=50K  \n",
      "38              0             0              40   United-States        <=50K  \n",
      "53              0             0              40   United-States        <=50K  \n",
      "28              0             0              40            Cuba        <=50K  \n",
      "     age     workclass  fnlwgt      education  education-num  \\\n",
      "age                                                            \n",
      "30    30     State-gov  141297      Bachelors             13   \n",
      "30    30   Federal-gov   59951   Some-college             10   \n",
      "30    30       Private  188146        HS-grad              9   \n",
      "30    30       Private   59496      Bachelors             13   \n",
      "30    30       Private   54334            9th              5   \n",
      "\n",
      "          marital-status          occupation    relationship  \\\n",
      "age                                                            \n",
      "30    Married-civ-spouse      Prof-specialty         Husband   \n",
      "30    Married-civ-spouse        Adm-clerical       Own-child   \n",
      "30    Married-civ-spouse   Machine-op-inspct         Husband   \n",
      "30    Married-civ-spouse               Sales         Husband   \n",
      "30         Never-married               Sales   Not-in-family   \n",
      "\n",
      "                    race    sex  capital-gain  capital-loss  hours-per-week  \\\n",
      "age                                                                           \n",
      "30    Asian-Pac-Islander   Male             0             0              40   \n",
      "30                 White   Male             0             0              40   \n",
      "30                 White   Male          5013             0              40   \n",
      "30                 White   Male          2407             0              40   \n",
      "30                 White   Male             0             0              40   \n",
      "\n",
      "     native-country gross-income  \n",
      "age                               \n",
      "30            India         >50K  \n",
      "30    United-States        <=50K  \n",
      "30    United-States        <=50K  \n",
      "30    United-States        <=50K  \n",
      "30    United-States        <=50K  \n"
     ]
    }
   ],
   "source": [
    "df_index_age = df.set_index('age',drop=False)\n",
    "\n",
    "print(df_index_age.index)\n",
    "print(df_index_age.head())\n",
    "\n",
    "print(df_index_age.loc[30].head()) # collect everyone with age 30 - the index is non-unique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3) select rows based on column condition"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 12,
>>>>>>> Stashed changes
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
<<<<<<< Updated upstream
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     workclass  fnlwgt      education  education-num  \\\n",
      "11   30     State-gov  141297      Bachelors             13   \n",
      "33   30   Federal-gov   59951   Some-college             10   \n",
      "59   30       Private  188146        HS-grad              9   \n",
      "60   30       Private   59496      Bachelors             13   \n",
      "88   30       Private   54334            9th              5   \n",
      "\n",
      "         marital-status          occupation    relationship  \\\n",
      "11   Married-civ-spouse      Prof-specialty         Husband   \n",
      "33   Married-civ-spouse        Adm-clerical       Own-child   \n",
      "59   Married-civ-spouse   Machine-op-inspct         Husband   \n",
      "60   Married-civ-spouse               Sales         Husband   \n",
      "88        Never-married               Sales   Not-in-family   \n",
      "\n",
      "                   race    sex  capital-gain  capital-loss  hours-per-week  \\\n",
      "11   Asian-Pac-Islander   Male             0             0              40   \n",
      "33                White   Male             0             0              40   \n",
      "59                White   Male          5013             0              40   \n",
      "60                White   Male          2407             0              40   \n",
      "88                White   Male             0             0              40   \n",
      "\n",
      "    native-country gross-income  \n",
      "11           India         >50K  \n",
      "33   United-States        <=50K  \n",
      "59   United-States        <=50K  \n",
      "60   United-States        <=50K  \n",
      "88   United-States        <=50K  \n",
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "32556    False\n",
      "32557    False\n",
      "32558    False\n",
      "32559    False\n",
      "32560    False\n",
      "Name: age, Length: 32561, dtype: bool\n",
      "    age workclass  fnlwgt      education  education-num       marital-status  \\\n",
      "8    31   Private   45781        Masters             14        Never-married   \n",
      "13   32   Private  205019     Assoc-acdm             12        Never-married   \n",
      "15   34   Private  245487        7th-8th              4   Married-civ-spouse   \n",
      "17   32   Private  186824        HS-grad              9        Never-married   \n",
      "38   31   Private   84154   Some-college             10   Married-civ-spouse   \n",
      "\n",
      "            occupation    relationship                 race      sex  \\\n",
      "8       Prof-specialty   Not-in-family                White   Female   \n",
      "13               Sales   Not-in-family                Black     Male   \n",
      "15    Transport-moving         Husband   Amer-Indian-Eskimo     Male   \n",
      "17   Machine-op-inspct       Unmarried                White     Male   \n",
      "38               Sales         Husband                White     Male   \n",
      "\n",
      "    capital-gain  capital-loss  hours-per-week  native-country gross-income  \n",
      "8          14084             0              50   United-States         >50K  \n",
      "13             0             0              50   United-States        <=50K  \n",
      "15             0             0              45          Mexico        <=50K  \n",
      "17             0             0              40   United-States        <=50K  \n",
      "38             0             0              38               ?         >50K  \n",
      "       age          workclass  fnlwgt      education  education-num  \\\n",
      "222     90            Private   51744        HS-grad              9   \n",
      "1040    90            Private  137018        HS-grad              9   \n",
      "1935    90            Private  221832      Bachelors             13   \n",
      "2303    90            Private   52386   Some-college             10   \n",
      "2891    90            Private  171956   Some-college             10   \n",
      "4070    90            Private  313986           11th              7   \n",
      "4109    90                  ?  256514      Bachelors             13   \n",
      "5104    90            Private   52386   Some-college             10   \n",
      "5272    90            Private  141758            9th              5   \n",
      "5370    90          Local-gov  227796        Masters             14   \n",
      "5406    90            Private   51744        Masters             14   \n",
      "6232    90   Self-emp-not-inc  155981      Bachelors             13   \n",
      "6624    90            Private  313986           11th              7   \n",
      "8562    49            Private  122066        HS-grad              9   \n",
      "8806    90            Private   87372    Prof-school             15   \n",
      "8963    90                  ?   77053        HS-grad              9   \n",
      "8973    90            Private   46786      Bachelors             13   \n",
      "10210   90   Self-emp-not-inc  282095   Some-college             10   \n",
      "10545   90            Private  175491        HS-grad              9   \n",
      "11512   90            Private   87285        HS-grad              9   \n",
      "11731   90                  ?   39824        HS-grad              9   \n",
      "11996   90            Private   40388      Bachelors             13   \n",
      "12451   90                  ?  225063   Some-college             10   \n",
      "12529   65            Private  172510   Some-college             10   \n",
      "12975   90            Private  250832           10th              6   \n",
      "13928   81   Self-emp-not-inc  123959      Bachelors             13   \n",
      "14159   90          Local-gov  187749     Assoc-acdm             12   \n",
      "15259   60            Private  114263      Bachelors             13   \n",
      "15356   90            Private   90523        HS-grad              9   \n",
      "15892   90            Private   88991      Bachelors             13   \n",
      "17144   28   Self-emp-not-inc  183523        HS-grad              9   \n",
      "17735   26            Private  358975   Some-college             10   \n",
      "18277   90            Private  311184      Bachelors             13   \n",
      "18413   90            Private  313749      Bachelors             13   \n",
      "18725   90          Local-gov  153602        HS-grad              9   \n",
      "18832   90            Private  115306        Masters             14   \n",
      "18839   66   Self-emp-not-inc  174995     Assoc-acdm             12   \n",
      "19212   90            Private  139660   Some-college             10   \n",
      "19489   90            Private   84553        HS-grad              9   \n",
      "19747   90            Private  226968        7th-8th              4   \n",
      "20610   90            Private  206667        Masters             14   \n",
      "21371   30            Private  207668      Bachelors             13   \n",
      "22220   90            Private   52386      Bachelors             13   \n",
      "22658   54            Private  188186        HS-grad              9   \n",
      "23023   24            Private  117779      Bachelors             13   \n",
      "24043   90   Self-emp-not-inc   82628        HS-grad              9   \n",
      "24238   90                  ?  166343        1st-4th              2   \n",
      "25303   90                  ?  175444        7th-8th              4   \n",
      "27041   57       Self-emp-inc  258883        HS-grad              9   \n",
      "27750   55            Private  143266      Assoc-voc             11   \n",
      "28463   90        Federal-gov  195433        HS-grad              9   \n",
      "30346   47            Private  180277        HS-grad              9   \n",
      "31030   90            Private   47929        HS-grad              9   \n",
      "31696   90                  ?  313986        HS-grad              9   \n",
      "32277   90            Private  313749        HS-grad              9   \n",
      "32367   90          Local-gov  214594        7th-8th              4   \n",
      "\n",
      "            marital-status          occupation     relationship  \\\n",
      "222          Never-married       Other-service    Not-in-family   \n",
      "1040         Never-married       Other-service    Not-in-family   \n",
      "1935    Married-civ-spouse     Exec-managerial          Husband   \n",
      "2303         Never-married       Other-service    Not-in-family   \n",
      "2891             Separated        Adm-clerical        Own-child   \n",
      "4070         Never-married   Handlers-cleaners        Own-child   \n",
      "4109               Widowed                   ?   Other-relative   \n",
      "5104         Never-married       Other-service    Not-in-family   \n",
      "5272         Never-married        Adm-clerical    Not-in-family   \n",
      "5370    Married-civ-spouse     Exec-managerial          Husband   \n",
      "5406         Never-married     Exec-managerial    Not-in-family   \n",
      "6232    Married-civ-spouse      Prof-specialty          Husband   \n",
      "6624    Married-civ-spouse        Craft-repair          Husband   \n",
      "8562    Married-civ-spouse     Exec-managerial          Husband   \n",
      "8806    Married-civ-spouse      Prof-specialty          Husband   \n",
      "8963               Widowed                   ?    Not-in-family   \n",
      "8973    Married-civ-spouse               Sales          Husband   \n",
      "10210   Married-civ-spouse     Farming-fishing          Husband   \n",
      "10545   Married-civ-spouse        Craft-repair          Husband   \n",
      "11512        Never-married       Other-service        Own-child   \n",
      "11731              Widowed                   ?    Not-in-family   \n",
      "11996        Never-married     Exec-managerial    Not-in-family   \n",
      "12451        Never-married                   ?        Own-child   \n",
      "12529              Widowed      Prof-specialty    Not-in-family   \n",
      "12975   Married-civ-spouse     Exec-managerial          Husband   \n",
      "13928              Widowed      Prof-specialty    Not-in-family   \n",
      "14159   Married-civ-spouse        Adm-clerical          Husband   \n",
      "15259             Divorced     Exec-managerial    Not-in-family   \n",
      "15356              Widowed    Transport-moving        Unmarried   \n",
      "15892   Married-civ-spouse     Exec-managerial             Wife   \n",
      "17144   Married-civ-spouse        Craft-repair          Husband   \n",
      "17735        Never-married     Priv-house-serv    Not-in-family   \n",
      "18277   Married-civ-spouse               Sales          Husband   \n",
      "18413        Never-married      Prof-specialty        Own-child   \n",
      "18725   Married-civ-spouse       Other-service          Husband   \n",
      "18832        Never-married     Exec-managerial        Own-child   \n",
      "18839   Married-civ-spouse        Craft-repair          Husband   \n",
      "19212             Divorced               Sales        Unmarried   \n",
      "19489   Married-civ-spouse   Machine-op-inspct          Husband   \n",
      "19747   Married-civ-spouse   Machine-op-inspct          Husband   \n",
      "20610   Married-civ-spouse      Prof-specialty             Wife   \n",
      "21371        Never-married        Tech-support    Not-in-family   \n",
      "22220        Never-married      Prof-specialty    Not-in-family   \n",
      "22658        Never-married       Other-service   Other-relative   \n",
      "23023        Never-married      Prof-specialty    Not-in-family   \n",
      "24043        Never-married     Exec-managerial    Not-in-family   \n",
      "24238              Widowed                   ?    Not-in-family   \n",
      "25303            Separated                   ?    Not-in-family   \n",
      "27041   Married-civ-spouse    Transport-moving          Husband   \n",
      "27750   Married-civ-spouse        Craft-repair          Husband   \n",
      "28463   Married-civ-spouse        Craft-repair          Husband   \n",
      "30346   Married-civ-spouse        Adm-clerical             Wife   \n",
      "31030   Married-civ-spouse   Machine-op-inspct          Husband   \n",
      "31696   Married-civ-spouse                   ?          Husband   \n",
      "32277              Widowed        Adm-clerical        Unmarried   \n",
      "32367   Married-civ-spouse     Protective-serv          Husband   \n",
      "\n",
      "                      race      sex  capital-gain  capital-loss  \\\n",
      "222                  Black     Male             0          2206   \n",
      "1040                 White   Female             0             0   \n",
      "1935                 White     Male             0             0   \n",
      "2303    Asian-Pac-Islander     Male             0             0   \n",
      "2891                 White   Female             0             0   \n",
      "4070                 White     Male             0             0   \n",
      "4109                 White   Female           991             0   \n",
      "5104    Asian-Pac-Islander     Male             0             0   \n",
      "5272                 White   Female             0             0   \n",
      "5370                 White     Male         20051             0   \n",
      "5406                 Black     Male             0             0   \n",
      "6232                 White     Male         10566             0   \n",
      "6624                 White     Male             0             0   \n",
      "8562                 White     Male             0             0   \n",
      "8806                 White     Male         20051             0   \n",
      "8963                 White   Female             0          4356   \n",
      "8973                 White     Male          9386             0   \n",
      "10210                White     Male             0             0   \n",
      "10545                White     Male          9386             0   \n",
      "11512                White   Female             0             0   \n",
      "11731                White     Male           401             0   \n",
      "11996                White     Male             0             0   \n",
      "12451   Asian-Pac-Islander     Male             0             0   \n",
      "12529                White   Female          1848             0   \n",
      "12975                White     Male             0             0   \n",
      "13928                White   Female             0          1668   \n",
      "14159   Asian-Pac-Islander     Male             0             0   \n",
      "15259                White   Female             0             0   \n",
      "15356                White     Male             0             0   \n",
      "15892                White   Female             0             0   \n",
      "17144                White     Male             0             0   \n",
      "17735                White   Female             0             0   \n",
      "18277                White     Male             0             0   \n",
      "18413                White   Female             0             0   \n",
      "18725                White     Male          6767             0   \n",
      "18832                White   Female             0             0   \n",
      "18839                White     Male          2290             0   \n",
      "19212                Black   Female             0             0   \n",
      "19489                White     Male             0             0   \n",
      "19747                White     Male             0             0   \n",
      "20610                White   Female             0             0   \n",
      "21371                White     Male             0             0   \n",
      "22220   Asian-Pac-Islander     Male             0             0   \n",
      "22658                White   Female             0             0   \n",
      "23023                White     Male             0             0   \n",
      "24043                White     Male          2964             0   \n",
      "24238                Black   Female             0             0   \n",
      "25303                White   Female             0             0   \n",
      "27041                White     Male          5178             0   \n",
      "27750                White     Male             0             0   \n",
      "28463                White     Male             0             0   \n",
      "30346                White   Female             0             0   \n",
      "31030                White     Male             0             0   \n",
      "31696                White     Male             0             0   \n",
      "32277                White   Female             0             0   \n",
      "32367                White     Male          2653             0   \n",
      "\n",
      "       hours-per-week  native-country gross-income  \n",
      "222                40   United-States        <=50K  \n",
      "1040               40   United-States        <=50K  \n",
      "1935               45   United-States        <=50K  \n",
      "2303               35   United-States        <=50K  \n",
      "2891               40     Puerto-Rico        <=50K  \n",
      "4070               40   United-States        <=50K  \n",
      "4109               10   United-States        <=50K  \n",
      "5104               35   United-States        <=50K  \n",
      "5272               40   United-States        <=50K  \n",
      "5370               60   United-States         >50K  \n",
      "5406               50   United-States         >50K  \n",
      "6232               50   United-States        <=50K  \n",
      "6624               40   United-States        <=50K  \n",
      "8562               30         Hungary        <=50K  \n",
      "8806               72   United-States         >50K  \n",
      "8963               40   United-States        <=50K  \n",
      "8973               15   United-States         >50K  \n",
      "10210              40   United-States        <=50K  \n",
      "10545              50         Ecuador         >50K  \n",
      "11512              24   United-States        <=50K  \n",
      "11731               4   United-States        <=50K  \n",
      "11996              55   United-States        <=50K  \n",
      "12451              10           South        <=50K  \n",
      "12529              20         Hungary        <=50K  \n",
      "12975              40   United-States        <=50K  \n",
      "13928               3         Hungary        <=50K  \n",
      "14159              20     Philippines        <=50K  \n",
      "15259              40         Hungary         >50K  \n",
      "15356              99   United-States        <=50K  \n",
      "15892              40         England         >50K  \n",
      "17144              50         Hungary        <=50K  \n",
      "17735              50         Hungary        <=50K  \n",
      "18277              20               ?        <=50K  \n",
      "18413              10   United-States        <=50K  \n",
      "18725              40   United-States        <=50K  \n",
      "18832              40   United-States        <=50K  \n",
      "18839              30         Hungary        <=50K  \n",
      "19212              37   United-States        <=50K  \n",
      "19489              40   United-States        <=50K  \n",
      "19747              40   United-States        <=50K  \n",
      "20610              40   United-States         >50K  \n",
      "21371              60         Hungary        <=50K  \n",
      "22220              40   United-States        <=50K  \n",
      "22658              20         Hungary        <=50K  \n",
      "23023              10         Hungary        <=50K  \n",
      "24043              12   United-States        <=50K  \n",
      "24238              40   United-States        <=50K  \n",
      "25303              15   United-States        <=50K  \n",
      "27041              60         Hungary         >50K  \n",
      "27750              50         Hungary         >50K  \n",
      "28463              30   United-States        <=50K  \n",
      "30346              40         Hungary        <=50K  \n",
      "31030              40   United-States        <=50K  \n",
      "31696              40   United-States         >50K  \n",
      "32277              25   United-States        <=50K  \n",
      "32367              40   United-States        <=50K  \n"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "# one condition\n",
    "#print(df[df['age']==30].head())\n",
    "# here is the condition: it's a boolean series - series is basically a dataframe with one column\n",
    "print(df['age']==30)\n",
    "\n",
    "# multiple conditions can be combined with & (and) | (or)\n",
<<<<<<< Updated upstream
    "#print(df[(df['age']>30)&(df['age']<35)].head())\n",
=======
    "print(df[(df['age']>30)&(df['age']<35)].head())\n",
>>>>>>> Stashed changes
    "print(df[(df['age']==90)|(df['native-country']==' Hungary')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Exercise 2\n",
    "How many people in adult_data.csv work at least 60 hours a week and have a doctorate?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('data/adult_data.csv') \n",
    "print(df1[(df1['education']==' Doctorate')&(df1['hours-per-week']>=60)].shape) "
   ]
>>>>>>> Stashed changes
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <font color='LIGHTGRAY'><center> Data transformations: pandas data frames </center></font>\n",
    "###  <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "   - <font color='LIGHTGRAY'>read in csv, excel, and sql data into a pandas data frame</font>\n",
    "   -  <font color='LIGHTGRAY'>filter rows in various ways</font>\n",
    "   -  **select columns**\n",
    "   -  <font color='LIGHTGRAY'>merge and append data frames</font>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country gross-income  \n",
      "0          2174             0              40   United-States        <=50K  \n",
      "1             0             0              13   United-States        <=50K  \n",
      "2             0             0              40   United-States        <=50K  \n",
      "3             0             0              40   United-States        <=50K  \n",
      "4             0             0              40            Cuba        <=50K  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
>>>>>>> Stashed changes
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "columns =  df.columns\n",
    "#print(columns)\n",
    "\n",
    "# select columns by column name\n",
    "#print(df[['age','hours-per-week']])\n",
    "#print(columns[[1,5,7]])\n",
    "#print(df[columns[[1,5,7]]])\n",
    "\n",
    "# select columns by index using iloc\n",
    "#print(df.iloc[:,3])\n",
    "\n",
    "# select columns by index - not standard python indexing\n",
    "#print(df.iloc[:,[3,5,6]])\n",
    "\n",
    "# select columns by index -  standard python indexing\n",
    "#print(df.iloc[:,::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               workclass       marital-status    relationship\n",
      "0              State-gov        Never-married   Not-in-family\n",
      "1       Self-emp-not-inc   Married-civ-spouse         Husband\n",
      "2                Private             Divorced   Not-in-family\n",
      "3                Private   Married-civ-spouse         Husband\n",
      "4                Private   Married-civ-spouse            Wife\n",
      "...                  ...                  ...             ...\n",
      "32556            Private   Married-civ-spouse            Wife\n",
      "32557            Private   Married-civ-spouse         Husband\n",
      "32558            Private              Widowed       Unmarried\n",
      "32559            Private        Never-married       Own-child\n",
      "32560       Self-emp-inc   Married-civ-spouse            Wife\n",
      "\n",
      "[32561 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[columns[[1,5,7]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color='LIGHTGRAY'><center> Data transformations: pandas data frames </center></font>\n",
    "###  <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "   - <font color='LIGHTGRAY'>read in csv, excel, and sql data into a pandas data frame</font>\n",
    "   -  <font color='LIGHTGRAY'>filter rows in various ways</font>\n",
    "   -  <font color='LIGHTGRAY'>select columns</font>\n",
    "   -  **merge and append data frames**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to merge dataframes?\n",
    "\n",
    "Merge - info on data points are distributed in multiple files"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 45,
>>>>>>> Stashed changes
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# We have two datasets from two hospitals\n",
    "\n",
    "hospital1 = {'ID':['ID1','ID2','ID3','ID4','ID5','ID6','ID7'],'col1':[5,8,2,6,0,2,5],'col2':['y','j','w','b','a','b','t']}\n",
    "df1 = pd.DataFrame(data=hospital1)\n",
    "print(df1)\n",
    "\n",
    "hospital2 = {'ID':['ID2','ID5','ID6','ID10','ID11'],'col3':[12,76,34,98,65],'col2':['q','u','e','l','p']}\n",
    "df2 = pd.DataFrame(data=hospital2)\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 47,
>>>>>>> Stashed changes
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  col1 col2_x  col3 col2_y\n",
      "0  ID1     5      y   NaN    NaN\n",
      "1  ID2     8      j  12.0      q\n",
      "2  ID3     2      w   NaN    NaN\n",
      "3  ID4     6      b   NaN    NaN\n",
      "4  ID5     0      a  76.0      u\n",
      "5  ID6     2      b  34.0      e\n",
      "6  ID7     5      t   NaN    NaN\n",
      "     ID  col1 col2_x  col3 col2_y\n",
      "0   ID2   8.0      j    12      q\n",
      "1   ID5   0.0      a    76      u\n",
      "2   ID6   2.0      b    34      e\n",
      "3  ID10   NaN    NaN    98      l\n",
      "4  ID11   NaN    NaN    65      p\n",
      "    ID  col1 col2_x  col3 col2_y\n",
      "0  ID2     8      j    12      q\n",
      "1  ID5     0      a    76      u\n",
      "2  ID6     2      b    34      e\n",
      "     ID  col1 col2_x  col3 col2_y\n",
      "0   ID1   5.0      y   NaN    NaN\n",
      "1   ID2   8.0      j  12.0      q\n",
      "2   ID3   2.0      w   NaN    NaN\n",
      "3   ID4   6.0      b   NaN    NaN\n",
      "4   ID5   0.0      a  76.0      u\n",
      "5   ID6   2.0      b  34.0      e\n",
      "6   ID7   5.0      t   NaN    NaN\n",
      "7  ID10   NaN    NaN  98.0      l\n",
      "8  ID11   NaN    NaN  65.0      p\n"
     ]
    }
   ],
   "source": [
    "# we are interested in only patients from hospital1\n",
    "df_left = df1.merge(df2,how='left',on='ID') # IDs from the left dataframe (df1) are kept\n",
    "print(df_left)\n",
    "\n",
    "# we are interested in only patients from hospital2\n",
    "df_right = df1.merge(df2,how='right',on='ID') # IDs from the right dataframe (df2) are kept\n",
    "print(df_right)\n",
    "\n",
    "# we are interested in patiens who were in both hospitals\n",
    "df_inner = df1.merge(df2,how='inner',on='ID') # merging on IDs present in both dataframes\n",
    "print(df_inner)\n",
    "\n",
    "# we are interested in all patients who visited at least one of the hospitals\n",
    "df_outer = df1.merge(df2,how='outer',on='ID')  # merging on IDs present in any dataframe\n",
    "print(df_outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to append dataframes?\n",
    "\n",
    "Append - new data comes in over a period of time. E.g., one file per month/quarter/fiscal year etc.\n",
    "\n",
    "\n",
    "You want to combine these files into one data frame."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 50,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  col1 col2  col3\n",
      "0   ID1   5.0    y   NaN\n",
      "1   ID2   8.0    j   NaN\n",
      "2   ID3   2.0    w   NaN\n",
      "3   ID4   6.0    b   NaN\n",
      "4   ID5   0.0    a   NaN\n",
      "5   ID6   2.0    b   NaN\n",
      "6   ID7   5.0    t   NaN\n",
      "0   ID2   NaN    q  12.0\n",
      "1   ID5   NaN    u  76.0\n",
      "2   ID6   NaN    e  34.0\n",
      "3  ID10   NaN    l  98.0\n",
      "4  ID11   NaN    p  65.0\n",
      "      ID  col1 col2  col3\n",
      "0    ID1   5.0    y   NaN\n",
      "1    ID2   8.0    j   NaN\n",
      "2    ID3   2.0    w   NaN\n",
      "3    ID4   6.0    b   NaN\n",
      "4    ID5   0.0    a   NaN\n",
      "5    ID6   2.0    b   NaN\n",
      "6    ID7   5.0    t   NaN\n",
      "7    ID2   NaN    q  12.0\n",
      "8    ID5   NaN    u  76.0\n",
      "9    ID6   NaN    e  34.0\n",
      "10  ID10   NaN    l  98.0\n",
      "11  ID11   NaN    p  65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m4/b06vyjd16rg6634q85_vdvl80000gn/T/ipykernel_86649/3063574832.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df1.append(df2) # note that rows with ID2, ID5, and ID6  are duplicated! Indices are duplicated too.\n",
      "/var/folders/m4/b06vyjd16rg6634q85_vdvl80000gn/T/ipykernel_86649/3063574832.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df1.append(df2,ignore_index=True) # note that rows with ID2, ID5, and ID6  are duplicated!\n"
     ]
    }
   ],
   "source": [
    "df_append = df1.append(df2) # note that rows with ID2, ID5, and ID6  are duplicated! Indices are duplicated too.\n",
    "print(df_append)\n",
    "\n",
    "df_append = df1.append(df2,ignore_index=True) # note that rows with ID2, ID5, and ID6  are duplicated! \n",
    "print(df_append)\n",
    "\n",
    "#d3 = {'ID':['ID23','ID94','ID56','ID17'],'col1':['rt','h','st','ne'],'col2':[23,86,23,78]}\n",
    "#df3 = pd.DataFrame(data=d3)\n",
    "#print(df3)\n",
    "\n",
    "#df_append = df1.append([df2,df3],ignore_index=True) # multiple dataframes can be appended to df1\n",
    "#print(df_append)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 52,
>>>>>>> Stashed changes
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_data_1 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "\n",
    "raw_data_2 = {\n",
    "        'subject_id': ['6', '7', '8', '9', '10'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "\n",
    "raw_data_3 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}\n",
    "\n",
    "# Create three data frames from raw_data_1, 2, and 3.\n",
    "# Append the first two data frames and assign it to df_append.\n",
    "# Merge the third data frame with df_append such that only subject_ids from df_append are present. \n",
    "# Assign the new data frame to df_merge. \n",
    "# How many rows and columns do we have in df_merge?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m4/b06vyjd16rg6634q85_vdvl80000gn/T/ipykernel_86649/1829464606.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_append = df_data_1.append(df_data_2,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_data_1 = pd.DataFrame(data=raw_data_1)\n",
    "df_data_2 = pd.DataFrame(data=raw_data_2)\n",
    "df_data_3 = pd.DataFrame(data=raw_data_3)\n",
    "\n",
    "df_append = df_data_1.append(df_data_2,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "# print(df_append.head())\n",
    "# print(df_data_3.head())\n",
    "df_merge = df_append.merge(df_data_3,how='left',on='subject_id')\n",
    "# print(df_merge.head())\n",
    "print(df_merge.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Always check that the resulting dataframe is what you wanted to end up with!\n",
    "- small toy datasets are ideal to test your code.\n",
    "\n",
    "### If you need to do a more complicated dataframe operation, check out pd.concat()!\n",
    "\n",
    "### We will learn how to add/delete/modify columns later when we learn about feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### By now, you are able to\n",
    "   - read in csv, excel, and sql data into a pandas data frame\n",
    "   - filter rows in various ways\n",
    "   - select columns\n",
    "   - merge and append data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mud card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
